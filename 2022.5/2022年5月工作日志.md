# 5.8
RNN代码\
GIRL理论\
GAN代码

# 5.9
PPO算法的证明\
TRPO/PPO笔记\
滑动平均\
广义优势函数\
PPO代码

# 5.10
sumo的学习，实例代码的编写\
MPC与RL的关系\
贝叶斯SVM的视角看SVM\

# 5.12
gym 的各种包装器\
pytorch lt库的学习\
python面向对象中typing的学习\
optuna学习

# 5.13
博弈论\
python精炼\
matplotlib精炼\
github创建仓库及使用\
Dataset、Tensordata、Datloader的代码

# 5.13
VAE项目代码：观测模型与PF滤波器代码的编写

# 5.15

1、python模块编程文件路径\
2、CNN\RNN\MLP的单元测试\
3、LSTM做交叉口控制的论文（输入时当前车和附近车的一个\状态向量序列）、输出是当前车的推荐速度 Multi-Agent Deep Reinforcement Learning to Manage Connected Autonomous Vehicles at Tomorrow’s Intersections\
![alt 属性文本](./图片/LSTM.png)
![alt 属性文本](./图片/LSTM网络.png)

4、MPC+RL，用DL学一个环境模型，然后随机撒点解MPC  Addressing crash-imminent situations caused by human driven vehicle errors in a mixed traffic stream: a model-based reinforcement learning approach for CAV\
![alt 属性文本](./图片/MPCRL.png)

5、交叉口MPC问题，由于约束太多不好解，把问题转化为无约束问题，然后用RL的方法学习一个状态s到a的映射。状态s被构造为41-d向量，由6-d自车状态、与自车存在潜在冲突的8辆车辆中的每辆车辆的4-d向量和参考路径的3-d向量组成（6+4*8+3），包括位置、速度和航向的跟踪误差 ,Learn collision-free self-driving skills at urban intersections with model-based reinforcement learning\

![alt 属性文本](./图片/关阳论文.png)


# 5.16 CPS会议
## 整个研究的流程是
### 1.定义需求：
1.利益攸关者需求\
2.安全需求\
3.战略需求\
4.服务需求\
5.标准化需求\
6.系统需求:产业级规划与分析（中心云）、区域交通应用（区域云）、边缘级车辆智能驾驶需求（边缘云）\
7.防护需求\
8.需求追溯关系（建立不同需求之间的追溯关系，也就是画一个邻接矩阵）

![alt 属性文本](./图片/需求分析.png)

### 2.定义功能：（不同场景对应不同功能）
1.安全功能\
2.标准化功能\
3.防护功能\
4.服务功能\
5.利益攸关者功能\
6.系统功能（我们关注的重点），我们重点关注车路协同智能驾驶（又可分为道路安全预警、智能驾驶、协同驾驶），其中道路安全预警这些模块又可以继续细分，对于组内涉及到的应用，我们把他的颗粒度可以做细（如果是感知黑盒的画就不考虑系统内部结构，如果是simulink模型，可以继续细化，这样可以形成追溯），对于组内不涉及的应用，可以不太关注，交给外包。
![alt 属性文本](./图片/系统工程3.png)
![alt 属性文本](./图片/系统工程1.png)
![alt 属性文本](./图片/系统工程2.png)
![alt 属性文本](./图片/路测设备信息传递.png)

7.
### 3.定义逻辑：（包含在功能定义之内了，对应较细的颗粒度，其实可以理解为是画一个状态机出来）

### 4.定义物理层：（同样在功能定义之内，可以理解为状态机内部更细的物理模型）


## NOTE：
杜老师的架构可以给我们直接复用，我们需要结合我们的应用再往下探，我需要把顶层的架构做填空，结合我们的东西做一下修改。\
他这个软件只能定义一些计算，如果涉及到矩阵计算矩阵切片等就不好弄了\
算法还是要用matlab或者python写\


# 5.17 
## 1统计学习课程总结
**1** .深度生成模型和深度判别模型是不同的，深度判别模型是传统的神经网络，比如CNN RNN等\
**2** .深度生成模型主要用在无监督任务和半监督任务上
**3** .VAE：主要关注重参数化技巧\
![alt 属性文本](./图片/重参数化技巧.png)
![alt 属性文本](./图片/重参数化技巧2.png)
![alt 属性文本](./图片/重参数化技巧3.png)

**4** .GAN：主要关注目标函数
![alt 目标函数](./图片/GAN-D目标函数.png)
<center> GAN-D判别器目标函数 </center>

![alt 目标函数](./图片/GAN-G目标函数.png)
<center> GAN-G生成器目标函数 </center>

![alt 目标函数](./图片/GAN合并目标函数.png)
<center> GAN-判别器生成器合并后的目标函数（其实是一种JS divergence between） </center>

**4.1** GAN的一些前沿Topic\
**(1)** 用控制论拉普拉斯变换来这证明稳定性\
**(2)** triple GAN ：用GAN来解决半监督学习问题\


**5.** FLOW模型：主要关注反函数原理\
**(1)** 我们有了p(z)的概率密度函数，我们又知道x=g(z)，现在我们想要求得x的概率密度函数，具体方法如下\
![alt 目标函数](./图片/FLOW1.png)
<center> det |雅可比矩阵| 表示雅可比矩阵的行列式的值 </center>

![alt 目标函数](./图片/FLOW2.png)
![alt 目标函数](./图片/FLOW3.png)
<center> FLOW模型一般假设的变换的形式很简单，主要是为了让雅可比矩阵为对角阵，这也导致模型的表示能力不强，所以需要多叠几层，这也是为什么称为“流”模型 </center>\

**(2)** FLOW模型有一个缺陷就是，每叠一层就要重新reshape到低维（输入的维度）这是为了保持雅可比矩阵为对角阵，这也导致网络变成  胖->瘦->胖->瘦交替的形式。VFLOW模型解决了这个问题，它不要求雅可比矩阵为对角阵，这样可以用更少的层数达到同样的效果。、
![alt 目标函数](./图片/VFLOW.png)

**6.** 珠算：概率编程库，从概率图的视角来编程\

## 2关于控制的一些感想
**7.** 开环控制与闭环控制\
开环控制是指在模型非常精确的情况下，给定初始状态，对于想要达到的目标状态，可知直接求得一个控制序列出来。\
闭环控制是指每次控制的时候参考当前的状态，也就是有状态反馈\

一个例子:\
MPC中在一个时域内预测的过程可以看作是一个开环控制（用当前状态，根据系统模型，往后预测n个状态，求出一个有n个控制量的序列，但是只作用第一个控制量）\
在时域与时域之间，也就是对应现实中两个状态，属于闭环控制，因为每一次控制都需要参考当前的状态，因此MPC可以说是时域内开环，整个系统闭环\

## 3代码实战
**8.** 数据集自定义流程(主要关注继承Dataset类时重写的方法、transform中数据增广的流程 -> 需要注意的是数据增强并不会增加数据集的数量，而是每次epoch时读进的去数据都是不一样的，即使你的dataloader写在了epoch循环的外边)\
**9.** Auto Encoder的代码实现\
**10.** VAE的代码实现\
（见[龙曲良老师实战代码](https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials)，[龙曲良老师实战课程](https://www.bilibili.com/video/BV11r4y1e76A?p=114&spm_id_from=pageDriver)）

## 4蒙特卡洛树搜索
**11.** MCTS的整体流程：MCTS其实是一种启发式搜索（通过较少的探索次数，找到目前最优的决策），相比于穷举效率更高，实际上也不可能穷举，因为探索空间非常大。所以MCTS通过一种高效的探索方式，在较少模拟次数下，就可以找到一种近似最优的决策。\
核心思想在UCB值的选择上\
从UCB公式中可以看到，在探索树的节点的过程中:\
一方面我希望选择价值较大的节点\
一方面我也希望选择没有探索过的节点，也就是$n_i$(被探索的次数)较小的节点（这是因为如果一味选择价值较大的，也就是说如果UCB只包括V，一些没有被探索的节点V初始值为0，那么它永远不会被探索，这是不合理的）
![alt 目标函数](./图片/MCTS算法过程.png)
![alt 目标函数](./图片/MCTS算法过程2.png)
![alt 目标函数](./图片/MCTS.png)
![alt 目标函数](./图片/探索过程举例.png)

算法的终止条件:可以到达一定时间终止，也可以达到一定探索次数终止。


# 5.18 
## 1.RNN的一些问题复盘
1.RNN如果在序列比较长的情况下会出现梯度消失和梯度爆炸的情况\
2.解决方案：
1）.解决梯度爆炸： 做clipping，如果梯度大于某一个值，就把它除以它的模，但是方向不变\
![alt 目标函数](./图片/clipping.png)
2）.解决梯度消失： LSTM(比RNN记得更长了，由于引入了输入门，输出门，遗忘门，使求梯度时的累乘变成了累加)\
![alt 目标函数](./图片/遗忘门.png)
<center> 遗忘门</center>

![alt 目标函数](./图片/输入门.png)
<center> 输入门</center>

![alt 目标函数](./图片/输出门.png)
<center> 输出门</center>

## 2.MPC的一些回顾
1.最优控制问题可以归纳为在约束下求costfunction最小的输入量的问题，传统最优控制只考虑当前部的costfunction，MPC相对于最优控制来说往后预测了多步，也就是考虑N步一个总的costfunction，希望求一个控制序列让总的costfunction最小，但是最后只应用第一个控制量\
![alt 目标函数](./图片/最优控制问题.png)

2.MPC的costfunction中是包含终止状态的代价的\
![alt 目标函数](./图片/MPC.png)
3.一般来说MPC的控制时域比预测时域少一步（这也是为什么会有一个终止状态代价），因为在控制的最后一步，给定k+N-1时刻的控制量以后，k+N-1时刻的状态会转移到k+N时刻的状态，这个状态就是最终状态，它也有一个代价。\
4.我们之所以说MPC既能做控制也能做规划的原因是：
（1）如果MPC只是跟随一条参考路径（这条参考路径已经规划好了，此路径上完全可行，没有障碍物），给的约束是很简单的一个控制量范围约束，那么这个可以理解为是一个控制问题\
（2）如果MPC跟随一条没有规划好的很粗略的参考路径（也就是routing的参考路径），在跟随的同时，对未来的状态做约束（比如和邻车距离要大于某一值，与障碍物距离大于某一值等），这样的过程可以等价为规划的过程，这样的约束下求出来的控制量相当于 规划+控制 结合在一起求出来的控制量。\

5.MPC步骤
![alt 目标函数](./图片/MPC1.png)
![alt 目标函数](./图片/MPC1.1.png)
![alt 目标函数](./图片/MPC2.png)
![alt 目标函数](./图片/MPC3.png)
![alt 目标函数](./图片/MPC4.png)
![alt 目标函数](./图片/MPC5.png)

X(K)已知，所以第一项可以省略

![alt 目标函数](./图片/MPC6.png)
![alt 目标函数](./图片/MPC7.png)
要计算的量：M,C,Q_bar,R_bar,G,E,H
![alt 目标函数](./图片/MPC求解.png)
转换为MATLAB可求解的方式，求出来的U_k是一个N个值   （0~N-1）的序列，只应用第一个。
Reference：[B站Dr_CAN](https://www.bilibili.com/video/BV1dv411M763/?spm_id_from=333.788.recommend_more_video.0)