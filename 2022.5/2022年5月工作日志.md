# 5.8
RNN代码\
GIRL理论\
GAN代码

# 5.9
PPO算法的证明\
TRPO/PPO笔记\
滑动平均\
广义优势函数\
PPO代码

# 5.10
sumo的学习，实例代码的编写\
MPC与RL的关系\
贝叶斯SVM的视角看SVM\

# 5.12
gym 的各种包装器\
pytorch lt库的学习\
python面向对象中typing的学习\
optuna学习

# 5.13
博弈论\
python精炼\
matplotlib精炼\
github创建仓库及使用\
Dataset、Tensordata、Datloader的代码

# 5.13
VAE项目代码：观测模型与PF滤波器代码的编写

# 5.15

1、python模块编程文件路径\
2、CNN\RNN\MLP的单元测试\
3、LSTM做交叉口控制的论文（输入时当前车和附近车的一个\状态向量序列）、输出是当前车的推荐速度 Multi-Agent Deep Reinforcement Learning to Manage Connected Autonomous Vehicles at Tomorrow’s Intersections\
![alt 属性文本](./图片/LSTM.png)
![alt 属性文本](./图片/LSTM网络.png)

4、MPC+RL，用DL学一个环境模型，然后随机撒点解MPC  Addressing crash-imminent situations caused by human driven vehicle errors in a mixed traffic stream: a model-based reinforcement learning approach for CAV\
![alt 属性文本](./图片/MPCRL.png)

5、交叉口MPC问题，由于约束太多不好解，把问题转化为无约束问题，然后用RL的方法学习一个状态s到a的映射。状态s被构造为41-d向量，由6-d自车状态、与自车存在潜在冲突的8辆车辆中的每辆车辆的4-d向量和参考路径的3-d向量组成（6+4*8+3），包括位置、速度和航向的跟踪误差 ,Learn collision-free self-driving skills at urban intersections with model-based reinforcement learning\

![alt 属性文本](./图片/关阳论文.png)


